---
title: "Homework 4"
author: "Brandon Chung, Jiaxin Zheng, Andreina Arias, and Stephanie Chiang"
date: "Fall 2025"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(mice)
library(corrplot)
library(dplyr)
library(e1071)
library(ggplot2)
library(gridExtra)
library(caret)
library(pROC)
library(kableExtra)

```

**OBJECTIVE**: To build multiple linear regression and binary logistic regression models on the training data to predict the probability that: 
- a person will crash their car 
- the amount of money it will cost if the person does crash their car


## 1. DATA EXPLORATION

Explore, analyze and model a data set containing approximately 8000 records representing a customer at an auto insurance company. Each record has two response variables. The first response variable, TARGET_FLAG, is a 1 or a 0. A “1” means that the person was in a car crash. A zero means that the person was not in a car crash. The second response variable is TARGET_AMT. This value is zero if the person did not crash their car. But if they did crash their car, this number will be a value greater than zero.

VARIABLE NAME DEFINITION THEORETICAL EFFECT

- INDEX Identification Variable (do not use) None
- TARGET_FLAG Was Car in a crash? 1=YES 0=NO None
- TARGET_AMT If car was in a crash, what was the cost None
- AGE Age of Driver Very young people tend to be risky. Maybe very old people also.
- BLUEBOOK Value of Vehicle Unknown effect on probability of collision, but probably effect the payout if there is a crash
- CAR_AGE Vehicle Age Unknown effect on probability of collision, but probably effect the payout if there is a crash
- CAR_TYPE Type of Car Unknown effect on probability of collision, but probably effect the payout if there is a crash
- CAR_USE Vehicle Use Commercial vehicles are driven more, so might increase probability of collision
- CLM_FREQ # Claims (Past 5 Years) The more claims you filed in the past, the more you are likely to file in the future
- EDUCATION Max Education Level Unknown effect, but in theory more educated people tend to drive more safely
- HOMEKIDS # Children at Home Unknown effect
- HOME_VAL Home Value In theory, home owners tend to drive more responsibly
- INCOME Income In theory, rich people tend to get into fewer crashes
- JOB Job Category In theory, white collar jobs tend to be safer
- KIDSDRIV # Driving Children When teenagers drive your car, you are more likely to get into crashes
- MSTATUS Marital Status In theory, married people drive more safely
- MVR_PTS Motor Vehicle Record Points If you get lots of traffic tickets, you tend to get into more crashes
- OLDCLAIM Total Claims (Past 5 Years) If your total payout over the past five years was high, this suggests future payouts will be high
- PARENT1 Single Parent Unknown effect
- RED_CAR A Red Car Urban legend says that red cars (especially red sports cars) are more risky. Is that true?
- REVOKED License Revoked (Past 7 Years) If your license was revoked in the past 7 years, you probably are a more risky driver.
- SEX Gender Urban legend says that women have less crashes then men. Is that true?
- TIF Time in Force People who have been customers for a long time are usually more safe.
- TRAVTIME Distance to Work Long drives to work usually suggest greater risk
- URBANICITY Home/Work Area Unknown
- YOJ Years on Job People who stay at a job for a long time are usually more safe

## 2. DATA PREPARATION 

```{r import}
train_df <- read.csv("https://raw.githubusercontent.com/Chung-Brandon/621-Data-Mining/refs/heads/main/insurance_training_data.csv")

test_df <- read.csv("https://raw.githubusercontent.com/Chung-Brandon/621-Data-Mining/refs/heads/main/insurance-evaluation-data.csv")
```

```{r clean}
# Clean column values and convert to appropriate data types
train_df <- train_df |>
  mutate(across(
    c(TARGET_FLAG, PARENT1, MSTATUS, SEX, EDUCATION, JOB, CAR_USE, CAR_TYPE, RED_CAR, REVOKED,  URBANICITY),
    ~ as.factor(gsub("z_|<", "", .x))
  )) |>
  mutate(across(
    c(INCOME, HOME_VAL, BLUEBOOK, OLDCLAIM),
    ~ as.numeric(gsub("[\\$,]", "", .x))
  ))

test_df <- test_df |>
  mutate(across(
    c(TARGET_FLAG, PARENT1, MSTATUS, SEX, EDUCATION, JOB, CAR_USE, CAR_TYPE, RED_CAR, REVOKED,  URBANICITY),
    ~ as.factor(gsub("z_|<", "", .x))
  )) |>
  mutate(across(
    c(INCOME, HOME_VAL, BLUEBOOK, OLDCLAIM),
    ~ as.numeric(gsub("[\\$,]", "", .x))
  ))

glimpse(train_df)
glimpse(test_df)
```

Next, we view at a summary of each features. We see majority values are 0.

```{r}
train_df |>
  summary() |>
  kable() |>
  kable_styling()
```


Both datasets feature 26 variables; the training set contains 8161 observations and the testing set has 2141.

There are 5 columns contain missing data. Since AGE is only missing in 6 rows, those observations can be dropped. For the rest of the variables, we can impute missing data using the MICE package.

```{r}
colSums(is.na(train_df))

train_df_imp <- train_df |> drop_na(AGE)
train_df_imp <- complete(mice(train_df_imp, m = 1, method = "pmm", seed = 123))

colSums(is.na(train_df_imp))
```

The testing data also had missing data used mice a well to impute missing data without imputing data to the target variables. The target variables were turned to empty strings to avoid mice from filling in those variables.
```{r}
# specify methods for each column
methVar <- make.method(test_df)

# set target columns to empty strings "" so mice will not touch them
methVar[methVar != ""] <- "pmm"
methVar["TARGET_FLAG"] <- ""
methVar["TARGET_AMT"]  <- ""

imp <- (mice(test_df, m = 1, method = methVar, seed = 123))
test_df_imp <- complete(imp)

test_df_imp$TARGET_AMT <- as.numeric(test_df$TARGET_AMT) #ensure the target variable is numeric

colSums(is.na(train_df_imp))
```

### Distributions

Now we can visualize the distributions for our target variables in the training set.

```{r}
ggplot(train_df_imp, aes(x = TARGET_FLAG, fill = TARGET_FLAG)) +
  geom_bar() +
  labs(
    title = "Distribution of Car Crash Involvement",
    x = "Target (0 = NO, 1 = YES)",
    y = "Count"
  )
```
- The distribution of TARGET_AMT is extremely right-skewd. 
- There are approximately 80% on the rows have a target amount of 0.

```{r}
ggplot(train_df_imp, aes(x = TARGET_AMT)) +
  geom_histogram(bins = 50) +
  labs(title = "Distribution of Car Crash Costs", x = "Value", y = "Frequency")
```

```{r}
ggplot(train_df_imp, aes(x = TARGET_AMT)) +
  geom_histogram(bins = 75) +
  scale_x_sqrt() +
  scale_y_sqrt() +
  labs(title = "Distribution of Car Crash Costs (Scaled)", x = "Value", y = "Frequency")
```

Distributions for some of the predictor variables can be seen below as well.
- The distribution profile show specifically right skew with long tails in variables INCOME, OLDCLAIM, BLUEBOOK, HOME_VAL,TARGET_AMT.These variable contain many small values and a small number of extremely large values, this indicating the presence of outliers.
- AGE, TRAVTIME, and YOJ are exhibit a mix of distribution shapes.


```{r}
# Select numeric columns
num_vars <- train_df_imp |>
  as_tibble() |>
  dplyr::select(where(is.numeric)) |>
  dplyr::select(-any_of(c("target", "INDEX")))

# Reshape to long format
long_df <- num_vars |>
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value")

# Histograms
ggplot(long_df, aes(x = value)) +
  geom_histogram(aes(y = ..density..), bins = 30) +
  facet_wrap(~ variable, scales = "free", ncol = 3) +
  labs(title = "Distributions of Numeric Predictor Variables", y = "", x = "")
```

- Several variables, such as INCOME, HOME_VAL, BLUEBOOK, and TARGET_AMT show a large spread and long right tails with many outliers, this is consistent with what was seen in the histograms above. 

- In contrast, variables such as AGE, YOJ, and TIF exhibit more compact and symmetric distributions, with fewer extreme values. 

```{r message=FALSE, warning=FALSE}
# Box plots
ggplot(long_df, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() +
  scale_y_log10() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Distributions of Numeric Predictor Variables (Scaled)", y = "", x = "")
```

And here is a correlation matrix for the numeric variables.


- The correlation heatmap shows that most numeric predictor variables in the dataset have very weak linear relationships with one another. The majority of correlation values fall between –0.10 and 0.30. This is helpful for regression modeling because it reduces instability in coefficient estimates.

#### A few moderate correlations appear:

- INCOME and HOME_VAL (≈ 0.58): Higher-income customers tend to live in higher-valued homes, which is expected.

- CLM_FREQ and OLDCLAIM (≈ 0.50): Customers with more past claims tend to have higher total past claim costs.

- HOME_VAL and BLUEBOOK (≈ 0.22): House value is weakly related to vehicle value.

- CAR_AGE and BLUEBOOK show a small negative correlation (≈ –0.15): Newer cars tend to have higher value.


```{r}
# Compute the correlation matrix
corr_matrix <- cor(num_vars)
corr_matrix[!is.finite(corr_matrix)] <- 0
hclust(as.dist(1 - corr_matrix))

# Plot correlation heatmap
corrplot(
  corr_matrix,
  method = "color",
  type = "upper", 
  order = "hclust",
  addCoef.col = "black", 
  tl.col = "black", 
  tl.srt = 45, 
  number.cex = 0.6,
  col = colorRampPalette(c("darkred", "white", "darkblue"))(200)
)
```

```{r}
# Get upper triangle of the correlation matrix
upper_tri <- upper.tri(corr_matrix)

# Find pairs with correlation > 0.8 (absolute)
high_corr_pairs <- which(abs(corr_matrix) > 0.8 & upper_tri, arr.ind = TRUE)

# Display variable pairs and their correlation
data.frame(
  Var1 = rownames(corr_matrix)[high_corr_pairs[, 1]],
  Var2 = colnames(corr_matrix)[high_corr_pairs[, 2]],
  Correlation = corr_matrix[high_corr_pairs]
)

```


Describe how you have transformed the data by changing the original variables or creating new variables. If you
did transform the data or create new variables, discuss why you did this. Here are some possible transformations.
a. b. c. d. e. Fix missing values (maybe with a Mean or Median value)
Create flags to suggest if a variable was missing
Transform data by putting it into buckets
Mathematical transforms such as log or square root (or use Box-Cox)
Combine variables (such as ratios or adding or multiplying) to create new variables


Some numerical variables seemed to be skewed such as: "INCOME", "TRAVTIME", "OLDCLAIM", "HOME_VAL" and "BLUEBOOK" were skewed to the right. Since right-skewed variables violate regression assumptions, we did a log tranformation to make the variables normally distributed. We transformed skewed numeric variables that were not count variables. For the transformation we just added new variables just in case we wanted to use the non-transformed variable for modeling. The transformation can help reduces sensitivity to outliers and help to stabilizes variance.

```{r}
Skewed_vars<- c("INCOME", "HOME_VAL", "BLUEBOOK", "OLDCLAIM", "TRAVTIME")
```

```{r}
#Applied log transformation using log(x+1) to avoid log(0)
for(v in Skewed_vars){
  new_name<-paste0(v,"_LOG")
  train_df_imp[[new_name]]<-log(train_df_imp[[v]]+1)
}
```

```{r}
#Also Applied transformation to test dataframe
for(v in Skewed_vars){
  new_name <- paste0(v, "_LOG")
  test_df_imp[[new_name]] <- log(test_df_imp[[v]] + 1)
}
```


Comparsion graph
```{r}
plot_list <- list()
  
for (v in Skewed_vars) {
  new_v <- paste0(v, "_LOG")

  p1 <- ggplot(train_df_imp, aes(x = .data[[v]])) +
    geom_histogram(aes(y = after_stat(density)), fill = "lightblue", color = "black", bins = 30) +
    ggtitle(paste0(v, " (Before Log)")) +
    theme_minimal()
  
  p2 <- ggplot(train_df_imp, aes(x = .data[[new_v]])) +
    geom_histogram(aes(y = after_stat(density)), fill = "lightgreen", color = "black", bins = 30) +
    ggtitle(paste0(v, " (After Log)")) +
    theme_minimal()
  
# Display graphs together
  grid.arrange(p1, p2, ncol = 2)
}
```



## 3. BUILD MODELS
Using the training data set, build at least two different multiple linear regression models and three different binary
logistic regression models, using different variables (or the same variables with different transformations). You
may select the variables manually, use an approach such as Forward or Stepwise, use a different approach such
as trees, or use a combination of techniques. Describe the techniques you used. If you manually selected a
variable for inclusion into the model or exclusion into the model, indicate why this was done.
Discuss the coefficients in the models, do they make sense? For example, if a person has a lot of traffic tickets,
you would reasonably expect that person to have more car crashes. If the coefficient is negative (suggesting that
the person is a safer driver), then that needs to be discussed. Are you keeping the model even though it is counter
intuitive? Why? The boss needs to know.


The three logistic regression models built to predict Target flag (whether a person will crash their car), full logistic model with all predictors, reduced logistic model, and tranformed logistic model; these models are differnt in complexity and interpretability which will allow us to compare performace and coefficients.

Logistic model for Target flag using all variables, as target flag is a binary variable. This model could be used for predicting crash probability. The coefficient show change in crash probability with each predictor, a positive coefficients means a higher crash probability and a negative coefficent would mean a lower crash probability. OLDClaim_LOG and CLM_FREQ had positive variables as expected but MVR_PTS should have been positive as well, but it was skewed to the right and not transformed as it is a count variable.


```{r}
# Removing Index from training and test data

train_df <- subset(train_df, select = -INDEX)
train_df_imp <- subset(train_df_imp, select = -INDEX)
test_df <- subset(test_df, select = -INDEX)

# Removing TARGET_AMT from data for logistic regression for TARGET_FLAG

train_df_log <- subset(train_df, select = -TARGET_AMT)
train_df_imp_log <- subset(train_df_imp, select = -TARGET_AMT)
test_df_log <- subset(test_df, select = -TARGET_AMT)
```

### Logistic Model 1: All Predictors Without Transformed


```{r}
logist_model1 <- glm(
  TARGET_FLAG ~ . - INCOME_LOG - HOME_VAL_LOG - BLUEBOOK_LOG - OLDCLAIM_LOG - TRAVTIME_LOG,
  data = train_df_imp_log,
  family = binomial
)

summary(logist_model1)
```


### Logistic Model 2: Reduced Predictors without Transformed

```{r}
logist_model2 <- step(logist_model1, direction = "backward")

```
```{r}
formula(logist_model2)
```

### Logistic Model 3: All Predictors with Transformations

```{r}
logist_model3 <- glm(
  TARGET_FLAG ~ . - INCOME - HOME_VAL - BLUEBOOK - OLDCLAIM - TRAVTIME,
  data = train_df_imp_log,
  family = binomial
)

summary(logist_model3)
```

### Logistic Model 4: Reduced Predictors with Transformations

```{r}
logist_model4 <- step(logist_model3, direction = "backward")
```

```{r}
formula(logist_model4)
```


### Linear Model 1: All Predictors Without Transformed

```{r}
# Removing TARGET_FLAG from training and testing data for linear modeling of TARGET_AMT

train_df_imp_lin <- subset(train_df_imp, select = -TARGET_FLAG)
test_df_lin <- subset(test_df, select = -TARGET_FLAG)
```

```{r}
linear_model1 <- lm(TARGET_AMT ~ .- INCOME_LOG - HOME_VAL_LOG - BLUEBOOK_LOG - OLDCLAIM_LOG - TRAVTIME_LOG, data = train_df_imp_lin)

summary(linear_model1)

```

### Linear Model 2: Reduced Predictors Without Transformed

```{r}
linear_model2<- step(linear_model1, direction = "backward")
summary(linear_model2)
```
```{r}
formula(linear_model2)
```

### Linear Model 3: All Predictors With Transformed

```{r}
linear_model3 <- lm(TARGET_AMT ~ .- INCOME - HOME_VAL - BLUEBOOK - OLDCLAIM - TRAVTIME, data = train_df_imp_lin)

summary(linear_model3)
```

### Linear Model 4: Reduced Predictors With Transformed

```{r}
linear_model4 <- step(linear_model3, direction = "backward")
summary(linear_model4)
```

```{r}
formula(linear_model4)
```


## 4. SELECT MODELS 
Decide on the criteria for selecting the best multiple linear regression model and the best binary logistic regression
model. Will you select models with slightly worse performance if it makes more sense or is more parsimonious?
Discuss why you selected your models.
For the multiple linear regression model, will you use a metric such as Adjusted R2, RMSE, etc.? Be sure to
explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other
relevant model output. Using the training data set, evaluate the multiple linear regression model based on (a)
mean squared error, (b) R2, (c) F-statistic, and (d) residual plots. For the binary logistic regression model, will you
use a metric such as log likelihood, AIC, ROC curve, etc.? Using the training data set, evaluate the binary logistic
regression model based on (a) accuracy, (b) classification error rate, (c) precision, (d) sensitivity, (e) specificity, (f)
F1 score, (g) AUC, and (h) confusion matrix. Make predictions using the evaluation data set.


### Assessing Logistic Models

Our logistic regression model 1

```{r}
compare_logistic_models <- function(models, data, response_var, threshold = 0.5) {

  results <- data.frame(
    Model = character(),
    AIC = numeric(),
    Accuracy = numeric(),
    Sensitivity = numeric(),
    Specificity = numeric(),
    stringsAsFactors = FALSE
  )
  
  for (i in seq_along(models)) {
    model <- models[[i]]
    model_name <- names(models)[i]
    
    # Predicted probabilities
    probs <- predict(model, newdata = data, type = "response")
    preds <- factor(ifelse(probs > threshold, 1, 0), levels = c(0, 1))

    
    # Actual values
    actual <- factor(data[[response_var]], levels = c(0, 1))

    
    # Confusion matrix
    cm <- confusionMatrix(as.factor(preds), as.factor(actual), positive = "1")
    
    # Append results
    results <- rbind(results, data.frame(
      Model = model_name,
      AIC = AIC(model),
      Accuracy = cm$overall["Accuracy"],
      Sensitivity = cm$byClass["Sensitivity"],
      Specificity = cm$byClass["Specificity"]
    ))
  }
  
  return(results)
}


models <- list(
  Full_Log = logist_model3,
  Full_NoLog = logist_model1,
  Reduced_Log = logist_model4,
  Reduced_NoLog = logist_model2
)


compare_logistic_models(models, train_df_imp_log, response_var = "TARGET_FLAG")


```

### Assessing Linear Models

Our linear model 2, the reduced model without transformed data performed the best with AIC and only very slightly worse on Rsquared. 

```{r}
model_comparison <- data.frame(
  Model = c("linear_model1", "linear_model2", "linear_model3", "linear_model4"),
  AIC = c(
    AIC(linear_model1),
    AIC(linear_model2),
    AIC(linear_model3),
    AIC(linear_model4)
  ),
  Adjusted_R2 = c(
    summary(linear_model1)$adj.r.squared,
    summary(linear_model2)$adj.r.squared,
    summary(linear_model3)$adj.r.squared,
    summary(linear_model4)$adj.r.squared
  )
)

print(model_comparison)

```

### Predictions

Predictions were made and saved to csv "Homework 4 Predictions". Logistic regression model 3 was used to predict car crash in variable TARGET_FLAG, and multiple linear regression model 2 was used to predict amount of claim for the car crash in variable TARGET_AMT. Multiple linear regression was only used on observations in the test data where our logistic regression predicts a car crash. Observations where there is not a predicted car crash defaults to a 0$ claim in TARGET_AMT. 

```{r}
# Generate predicted probabilities
probs <- predict(logist_model3, newdata = test_df_imp, type = "response")

# Convert to binary predictions using a threshold (e.g., 0.5)
preds <- ifelse(probs > 0.5, 1, 0)

# Add predictions to your test data frame
test_df_imp$TARGET_FLAG <- preds

```

```{r}
# Predict claim amount only for predicted claimants
test_df_imp$TARGET_AMT <- ifelse(
  test_df_imp$TARGET_FLAG == 1,
  predict(linear_model2, newdata = test_df_imp),
  0
)

```

```{r}
# Creating predictions df
testdf_predictions <- test_df_imp
```

```{r}
# Predicted Values for TARGET_FLAG and TARGET_AMT
testdf_predictions$TARGET_FLAG
```

```{r}
testdf_predictions$TARGET_AMT
```
```{r}
# writing predictions to csv

write.csv(testdf_predictions, "Homework 4 Predictions")
```









